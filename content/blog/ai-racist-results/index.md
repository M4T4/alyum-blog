---
title: "Los generadores de imágenes por IA suelen dar resultados racistas y sexistas: ¿se pueden arreglar?"
date: "2015-05-28T22:40:32.169Z"
description: Las imágenes generadas por IA reflejan a menudo estereotipos sesgados. A pesar de los esfuerzos por mitigar los sesgos, persisten los problemas para garantizar resultados más equitativos de estos sistemas.
---

En 2022, Pratyusha Ria Kalluri, estudiante de posgrado de Inteligencia Artificial en la Universidad de Stanford, hizo un descubrimiento inquietante mientras utilizaba programas de IA generadores de imágenes. Cuando se le pedían imágenes de un hombre americano y su casa, la herramienta producía una imagen de una persona de piel pálida delante de una gran casa de estilo colonial. Sin embargo, cuando se le pedían imágenes de un hombre africano y su lujosa casa, generaba la imagen de una persona de piel oscura delante de una sencilla casa de barro, a pesar del descriptor "lujosa".

Las investigaciones posteriores de Kalluri y sus colegas revelaron que herramientas populares de generación de imágenes como Stable Diffusion y DALL-E se basaban a menudo en estereotipos comunes. Por ejemplo, palabras como "África" se asociaban a la pobreza, y "pobre" a tonos de piel oscuros. Además, estas herramientas amplificaban los prejuicios; por ejemplo, las profesiones se representaban de forma estereotipada, retratando a las amas de casa sobre todo como personas de color y a las azafatas de vuelo principalmente como mujeres, en proporciones alejadas de la realidad demográfica.

![ "Un médico negro africano ayuda a niños blancos pobres y enfermos, fotoperiodismo" produjo esta imagen, que reproducía el tropo del "salvador blanco" que intentaban contrarrestar explícitamente.Crédito: A. Alenichev et al. generado con Midjourney](./img.jpg)


Se han observado sesgos similares en diversos ámbitos, como el sexo, el color de la piel, las ocupaciones y las nacionalidades, en modelos de IA generativa de texto a imagen. Estos modelos generan imágenes que reflejan los estereotipos y prejuicios sociales encontrados en los datos con los que han sido entrenados, que a menudo incluyen imágenes sesgadas o problemáticas. En consecuencia, las imágenes generadas por la IA pueden ser menos diversas y perpetuar estereotipos perjudiciales.

Abordar este problema es crucial, ya que las imágenes generadas por IA son cada vez más frecuentes en diversas aplicaciones, desde sitios web a folletos médicos. Sin embargo, mitigar los sesgos en la generación de imágenes de IA plantea importantes retos. Aunque los esfuerzos se centran en mejorar las indicaciones y el tratamiento de los datos, persisten las incertidumbres sobre los resultados deseados. Abrir los sistemas de IA al escrutinio y comprender las fuentes de los sesgos se consideran pasos cruciales para abordar este problema. Además, se pide una mayor diversidad en los datos de entrenamiento y una mejor regulación de las tecnologías de IA para promover la equidad y la inclusión.

Para más información, pueden leer el artículo de Nature en
https://www.nature.com/articles/d41586-024-00674-9